{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![header](https://i.imgur.com/I4ake6d.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COPERNICUS MARINE PHYSICAL BLACK SEA TRAINING\n",
    "\n",
    "<div style=\"text-align: right\"><i> 07-00-PHY </i></div>\n",
    "\n",
    "***\n",
    "\n",
    "<center><h1>Notions on how to visualize maps of Temperature (T), Salinity (S) and Mixed Layer Depth (MLD), compute  density and plot transects. Understanding Black Sea dynamics from timeseries and regional analysis</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Table of contents\n",
    "- [Introduction](#1\\)-Introduction)\n",
    "- [About the data](#2\\)-About-the-data)\n",
    "- [Required Python modules](#3\\)-Required-Python-modules)\n",
    "- [Exercise n.1: Plot of maps](#4\\)-Exercise-n.1:-Plot-of-maps)\n",
    "- [Exercise n.2: Plot of transects](#5\\)-Exercise-n.2:-Plot-of-transects)\n",
    "- [Exercise n.3: T, S, UV forecast timeseries at a given location](#6\\)-Exercise-n.3:-T,-S,-UV-forecast-timeseries-at-a-given-location)\n",
    "- [Exercise n.4: Regional analysis using reanalysis product](#7\\)-Exercise-n.4:-Regional-analysis-using-reanalysis-product)\n",
    "- [Conclusion](#8\\)-Conclusion)\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go back to the \"Table of contents\"](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this exercise is to use the CMEMS BS-MFC model products to visualize the main physical fields in the Black Sea. \n",
    "\n",
    "In particular, you will display:\n",
    "- horizontal maps of the different 2D and 3D variables, the latter also at different depths avaraged on one month (March 2020)\n",
    "- vertical sections of temperature, salinity and density along a transect in the Black Sea highlighting the vertical structure of these fields\n",
    "- timeseries of temperature, salinity, currents (intensity and direction) in a given location using using hourly and daily forecast data\n",
    "- maps for temperature, salinity and currents: maximum/minimum and standard deviation on the Western basin using reanalysis products\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) About the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go back to the \"Table of contents\"](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1) Analysis and Forecast Data for Exercises 1-3\n",
    "\n",
    "### Exercises 1-3 are based on the product whose Identifier is: [BLKSEA_ANALYSIS_FORECAST_PHYS_007_001](https://resources.marine.copernicus.eu/?option=com_csw&task=results?option=com_csw&view=details&product_id=BLKSEA_ANALYSIS_FORECAST_PHYS_007_001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The physical component of the Black Sea near real time system (BS-PHY NRT) is based on a hydrodynamic model implemented over the whole Black Sea basin. The model horizontal grid resolution is 1/36° in meridional direction, 1/27° in zonal direction (ca. 3 km) and has 31 unevenly spaced vertical levels. The hydrodynamics is supplied by the Nucleus for European Modeling of the Ocean (NEMO, v3.4).The model solutions are corrected by the variational assimilation (based on a 3DVAR scheme), originally developed for the Mediterranean Sea and later extended for the global ocean. The observations assimilated in the BS-PHY NRT includes in-situ profiles, along-track sea level anomalies (SLA) and gridded sea surface temperature (SST) provided by Copernicus TAC.\n",
    "\n",
    "<img src=\"./img/BLKSEA_ANALYSIS_FORECAST_PHYS_007_001_table.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get more info on the product \n",
    "\n",
    "1. You can find info on this product and access to the download services in the [dedicated Product Page on Copernicus Marine (CMEMS) Web portal](https://resources.marine.copernicus.eu/?option=com_csw&task=results?option=com_csw&view=details&product_id=BLKSEA_ANALYSIS_FORECAST_PHYS_007_001)\n",
    "<br><br>\n",
    "2. For **detailed information** about the product, please consult the **document**: [Product User Manual (PUM)](./docs/ProductUserManuals/CMEMS-BS-PUM-007-001.pdf)\n",
    "<br><br>\n",
    "3. For information about **the quality and validation** of the product, please consult the **document**: [Quality Information Document (QUID)](./docs/QualityInformationDocuments/CMEMS-BS-QUID-007-001.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters used for downloading the data\n",
    "| Parameter | Value |\n",
    "| :---: | :---|\n",
    "| **Product** | BLKSEA_ANALYSIS_FORECAST_PHYS_007_001 |\n",
    "| **Datasets** | <ul><li>bs-cmcc-tem-an-fc-d</li><li>bs-cmcc-sal-an-fc-d</li><li>bs-cmcc-mld-an-fc-d</li><li>bs-cmcc-cur-an-fc-d</li><li>bs-cmcc-tem-an-fc-h</li><li>bs-cmcc-sal-an-fc-h</li><li>bs-cmcc-cur-an-fc-h</li></ul> |\n",
    "| **Frequency** | daily |\n",
    "| **Lat min** | 40.86 |\n",
    "| **Lat max** | 46.80 |\n",
    "| **Lon min** | 27.32 |\n",
    "| **Lon max** | 41.96 | \n",
    "| **Timesteps** | 2020-03-01, 2020-03-31 |\n",
    "| **Service for downloading** | FTP |\n",
    " **Files total dimension** | ~205 MB |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <b>Get the CMEMS User credentials</b>\n",
    "<hr>\n",
    "The data are already available on this notebook. But if you want to download the data by yourself, please be sure to have by your CMEMS User credentials. Otherwise please get them <a href=\"http://marine.copernicus.eu/services-portfolio/register-now/\" target=\"_blank\">here</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***How to download the products?***\n",
    "\n",
    "If you need some help about the different services for downloading the CMEMS products, please check this [tutorial](\n",
    "https://marine.copernicus.eu/tutorials/how-to-download-products-service-release-septembre-2015/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2) Reanalysis Data for Exercises 4\n",
    "\n",
    "### Exercise 4 is based on the product whose Identifier is: [BLKSEA_REANALYSIS_PHYS_007_004](https://resources.marine.copernicus.eu/?option=com_csw&task=results?option=com_csw&view=details&product_id=BLKSEA_REANALYSIS_PHYS_007_004)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the nominal multi year physical product for Black Sea (BS-PHY MY). It is provided over the same grid of the BS-PHY NRT system. The hydrodynamics are supplied by the Nucleus for European Modeling of the Ocean (NEMO, v3.4) online coupled with the variational assimilation - 3DVAR - scheme. The observations assimilated in the BS-PHY MY includes in-situ profiles provided by the U.K. MetOffice Hadley Center and along-track sea level anomalies (SLA) and gridded sea surface temperature (SST) provided by CMEMS TACs. The period covered by the BS-PHY MY products is Jan 1992-Jun 2018. \n",
    "\n",
    "<img src=\"./img/BLKSEA_REANALYSIS_PHYS_007_004_table.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get more info on the product\n",
    "\n",
    "1. You can find info on this product and access to the download services in the [dedicated Product Page on Copernicus Marine (CMEMS) Web portal](https://resources.marine.copernicus.eu/?option=com_csw&task=results?option=com_csw&view=details&product_id=BLKSEA_REANALYSIS_PHYS_007_004)\n",
    "<br><br>\n",
    "2. For **detailed information** about the product, please consult the **document**: [Product User Manual (PUM)](./docs/ProductUserManuals/CMEMS-BS-PUM-007-004.pdf)\n",
    "<br><br>\n",
    "3. For information about **the quality and validation** of the product, please consult the **document**: [Quality Information Document (QUID)](./docs/QualityInformationDocuments/CMEMS-BS-QUID-007-004.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters used for downloading the data\n",
    "| Parameter | Value |\n",
    "| :---: | :---|\n",
    "| **Product** | BLKSEA_REANALYSIS_PHYS_007_004 |\n",
    "| **Datasets** | <ul><li>sv04-bs-cmcc-tem-rean-d</li><li>sv04-bs-cmcc-sal-rean-d</li><li>sv04-bs-cmcc-cur-rean-d</li></ul> |\n",
    "| **Frequency** | daily |\n",
    "| **Lat min** | 40.86 |  \n",
    "| **Lat max** | 46.80 |  \n",
    "| **Lon min** | 27.5 |  \n",
    "| **Lon max** | 29.5 |  \n",
    "| **Depth**   | 2.5, 70 |  \n",
    "| **Timesteps** | 2009-01-01, 2018-12-31 |\n",
    "| **Service for downloading** | SUBSETTER |\n",
    "| **Files total dimension** | ~445 MB |  \n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Required Python modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go back to the \"Table of contents\"](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Module name | Description |\n",
    "| :---: | :---|\n",
    "| **os** | [Miscellaneous operating system interfaces](https://docs.python.org/3.7/library/os.html) for managing paths, creating directories,... |\n",
    "| **glob** | [Unix style pathname pattern expansion](https://docs.python.org/3.7/library/glob.html) this module finds all the pathnames matching a specified pattern according to the rules used by the Unix shell |\n",
    "| **numpy** | [NumPy](https://numpy.org/) is the fundamental package for scientific computing with Python and for managing ND-arrays |\n",
    "| **xarray** | [Xarray](http://xarray.pydata.org/en/stable/) introduces labels in the form of dimensions, coordinates and attributes on top of raw NumPy-like arrays, which allows for a more intuitive, more concise, and less error-prone developer experience. |\n",
    "| **matplotlib** |[Matplotlib](https://matplotlib.org/) is a Python 2D plotting library which produces publication quality figures |\n",
    "| **basemap** |[The matplotlib basemap toolkit](https://matplotlib.org/basemap/) is a library for plotting 2D data on maps in Python. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important module used in this example is **gsw** (Gibbs-SeaWater).\n",
    "\n",
    "The [Gibbs-SeaWater (GSW) Oceanographic Toolbox](http://www.teos-10.org/software.htm) contains the TEOS-10 subroutines for evaluating the thermodynamic properties of pure water (using IAPWS-09) and seawater (using IAPWS-08 for the saline part). The GSW library does not provide properties of ice or moist air (these properties can be found in the SIA library). This GSW Oceanographic Toolbox does not adhere to strict basic-SI units but rather oceanographic units are adopted. [website]\n",
    "\n",
    "This Python implementation of the Thermodynamic Equation of Seawater 2010 (TEOS-10) is based primarily on numpy ufunc wrappers of the GSW-C implementation. We expect it to replace the original python-gsw pure-python implementation after a brief overlap period. The primary reasons for this change are that by building on the C implementation we reduce code duplication and we gain an immediate update to the 75-term equation. Additional benefits include a major increase in speed, a reduction in memory usage, and the inclusion of more functions. The penalty is that a C (or MSVC C++ for Windows) compiler is required to build the package from source.\n",
    "\n",
    "**Warning: this is for Python >=3.5 only.**\n",
    "\n",
    "*References*:\n",
    "\n",
    "[gsw python GitHub](https://github.com/TEOS-10/GSW-Python)\n",
    "\n",
    "[Documentation on GSW-Python](https://teos-10.github.io/GSW-Python)\n",
    "\n",
    "[Documentation on gsw.density](https://teos-10.github.io/GSW-Python/density.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code cells allow you to enter and run Python code\n",
    "Run a code cell using <code>Shift-Enter</code> or pressing the <button class=\"btn btn-default btn-xs\"><i class=\"icon-play fa fa-play\"></i></button> button in the toolbar above:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install the needed Python modules (for local installation, can be skipped during Training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Requirement: Python version 3.7**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check your Python version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If needed you can install the right Python version in this way:\n",
    "```\n",
    "conda install python=3.7\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are using the standard *Anaconda* installation, you can install the modules executing the following command in a new cell:\n",
    "```\n",
    "conda install numpy xarray matplotlib basemap netcdf4 basemap-data-hires dask\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now install the **gsw** package which belongs to the channel **conda-forge**:\n",
    "```\n",
    "conda install -c conda-forge gsw\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, as requested, please restart the kernel.\n",
    "\n",
    "The kernel maintains the state of a notebook's computations. You can reset this state by restarting the kernel. This is done by clicking on the <button class=\"btn btn-default btn-xs\"><i class=\"fa fa-repeat icon-repeat\"></i></button> in the toolbar above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Exercise n.1: Plot of maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go back to the \"Table of contents\"](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For avoiding the warning messages during the execution and installation process, at first remove them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.basemap import Basemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gsw.density as density"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Don't change the following constants, which define the training and the notebook codes*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION_CODE = \"07\"\n",
    "NB_CODE = \"01\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**checkDir**: function for creating a path, if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkDir(outPath):\n",
    "    if not os.path.exists(outPath):\n",
    "        os.makedirs(outPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**getRangeIndexes**: function for getting the indexes of the array *arr* between the *var_min* and *var_max* values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRangeIndexes(arr, var_min, var_max):\n",
    "    return np.where((arr >= var_min) & (arr <= var_max))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for netcdf files\n",
    "data_path = './data/exercise1-2'\n",
    "# Path for the output files (images, etc)\n",
    "out_path = './out/'+REGION_CODE+'-'+NB_CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the current directories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories\n",
    "checkDir(data_path)\n",
    "checkDir(out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the new directories have been created... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir('.'):\n",
    "    print(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and if the data files are available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(data_path):\n",
    "    print(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input netcdf file\n",
    "\n",
    "# Daily means of March 2020\n",
    "tem_f = \"202003*_d-CMCC--TEMP-BSeas3-BS-b*_an-sv09.00.nc\"\n",
    "sal_f = \"202003*_d-CMCC--PSAL-BSeas3-BS-b*_an-sv09.00.nc\"\n",
    "mld_f = \"202003*_d-CMCC--AMXL-BSeas3-BS-b*_an-sv09.00.nc\"\n",
    " \n",
    "# Build the complete nc path\n",
    "tem_nc = glob.glob(os.path.join(data_path, tem_f))\n",
    "sal_nc = glob.glob(os.path.join(data_path, sal_f))\n",
    "mld_nc = glob.glob(os.path.join(data_path, mld_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the nc dataset\n",
    "tem_ds = xr.open_mfdataset(tem_nc, combine='by_coords')\n",
    "sal_ds = xr.open_mfdataset(sal_nc, combine='by_coords')\n",
    "mld_ds = xr.open_mfdataset(mld_nc, combine='by_coords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get info about the dataset for \"Potential Temperature\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tem_ds.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And about the variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tem_ds.data_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... the coordinates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tem_ds.coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    \n",
    "**The dataset is 3D! You have depth levels!**\n",
    "\n",
    "The xarray dataset ***temp_ds*** is extracted from the dataset ***bs-cmcc-tem-an-fc-d***  which is a **3D dataset**        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to check the depth levels. Type ```tem_ds.depth``` in the cell below and execute it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tem_ds.depth "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get info about the dataset opened \"Salinity\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sal_ds.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And about the variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sal_ds.data_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... the coordinates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sal_ds.coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get info about the dataset for \"Mixed Layer Depth\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mld_ds.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And about the variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mld_ds.data_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... the coordinates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mld_ds.coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Press the ***TAB*** key (on your keyboard) for obtaining the other methods and properties of the dataset: \n",
    "\n",
    "Select the cell below, press enter and then type:\n",
    "```\n",
    "mld_ds. (and press TAB)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the coordinate names (used later for accessing the data)\n",
    "lon_name = \"lon\"\n",
    "lat_name = \"lat\"\n",
    "time_name = \"time\"\n",
    "depth_name = \"depth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the variable names\n",
    "tem_name = \"thetao\"\n",
    "sal_name = \"so\"\n",
    "mld_name = \"mlotst\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the variables for the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Choose the variable to plot (but comment the others with the symbol #): ---\n",
    "#var_sel = tem_ds[tem_name]\n",
    "#var_sel = sal_ds[sal_name]\n",
    "var_sel = mld_ds[mld_name]\n",
    "\n",
    "dataset_3D = False\n",
    "if depth_name in var_sel.coords:\n",
    "    dataset_3D = True\n",
    "\n",
    "# --- Set up the arrays of coordinates for the selected dataset ---\n",
    "# \n",
    "lats = var_sel[lat_name]\n",
    "lons = var_sel[lon_name]\n",
    "times = var_sel[time_name]\n",
    "depths = var_sel[depth_name] if dataset_3D else []\n",
    "\n",
    "# --- Set the area: choose the min and max values for the coordinates ---\n",
    "# (and comment with the symbol # the unnecessary ones!):                                                               \n",
    "                                                                 \n",
    "# # Set lat-lon limits - CUSTOM\n",
    "# lon_min = 13.5\n",
    "# lon_max = 16\n",
    "# lat_min = 43.6-1 # 38\n",
    "# lat_max = 43.6+1\n",
    "\n",
    "# Set lat-lon limits - FULL AREA\n",
    "lat_min = lats.min()\n",
    "lat_max = lats.max()\n",
    "lon_min = lons.min()\n",
    "lon_max = lons.max()\n",
    "\n",
    "# Set the variable min and max values for the plot and the colorbar (otherwise assign None):\n",
    "min_value, max_value = None, None #authomatic colobar limits\n",
    "#min_value, max_value = 0, 25\n",
    "\n",
    "# Set the desired depth (in meters)\n",
    "d = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot configuration\n",
    "width_inch = 16\n",
    "height_inch = 8\n",
    "\n",
    "# Map configuration\n",
    "map_config = { \n",
    "#     \"projection\": \"merc\",\n",
    "    \"llcrnrlat\": lat_min,\n",
    "    \"llcrnrlon\": lon_min,\n",
    "    \"urcrnrlat\": lat_max,\n",
    "    \"urcrnrlon\": lon_max,\n",
    "    \"resolution\": 'i',\n",
    "    \"epsg\": 4326\n",
    "}\n",
    "\n",
    "# Axes labels\n",
    "fontsize = 14\n",
    "xlabel = 'longitude [deg]'\n",
    "ylabel = 'latitude [deg]'\n",
    "xlabelpad = 30\n",
    "ylabelpad = 60\n",
    "\n",
    "# Colorbar configuration\n",
    "cmap = \"jet\"\n",
    "cbar_position = \"right\"\n",
    "\n",
    "title_fontstyle = {\n",
    "    \"fontsize\": \"14\",\n",
    "    \"fontstyle\": \"italic\",\n",
    "    \"fontweight\": \"bold\",\n",
    "    \"pad\": 30\n",
    "}\n",
    "\n",
    "label_fontstyle = {\n",
    "    \"fontsize\": \"12\",\n",
    "    \"labelpad\": 30\n",
    "}\n",
    "\n",
    "# Set the coordinates indexes\n",
    "lat_indexes = getRangeIndexes(lats, lat_min, lat_max)\n",
    "lon_indexes = getRangeIndexes(lons, lon_min, lon_max)\n",
    "depth_indexes = [0]\n",
    "\n",
    "# Get the selected coordinates:\n",
    "lats_sel = lats[lat_indexes]\n",
    "lons_sel = lons[lon_indexes]\n",
    "\n",
    "#Avarage \n",
    "var_sel = var_sel.mean('time', keep_attrs=True)\n",
    " \n",
    "if dataset_3D:\n",
    "    data = var_sel[:, lat_indexes, lon_indexes].sel(depth=d,method='nearest')\n",
    "else: \n",
    "    data = var_sel[lat_indexes, lon_indexes]\n",
    "\n",
    "plt.figure(figsize=(width_inch, height_inch))\n",
    "\n",
    "map = Basemap(**map_config)\n",
    "\n",
    "## contour fill\n",
    "min_value = data.min().compute() if min_value is None else min_value\n",
    "max_value = data.max().compute() if max_value is None else max_value\n",
    "step_value = 0.5\n",
    "contour_levels = np.arange(min_value, max_value, step_value)\n",
    "# map.contourf(xx, yy, data, contour_levels, cmap=cmap)\n",
    "\n",
    "## pcolormesh\n",
    "x = np.linspace(0, map.urcrnrx, data.shape[1])\n",
    "y = np.linspace(0, map.urcrnry, data.shape[0])\n",
    "    \n",
    "xx, yy = np.meshgrid(lons_sel, lats_sel)\n",
    "    \n",
    "#     colormesh = map.pcolormesh(xx, yy, data, cmap=cmap)\n",
    "colormesh = map.pcolormesh(xx, yy, data, vmin=min_value, vmax=max_value, cmap=cmap)\n",
    "    \n",
    "## draw meridians and parallels\n",
    "step_lat = float((lat_max - lat_min) / 5)\n",
    "step_lon = float((lon_max - lon_min) / 5)\n",
    "\n",
    "parallels = np.arange(lat_min, lat_max, step_lat)\n",
    "meridians = np.arange(lon_min, lon_max, step_lon) \n",
    "\n",
    "map.drawmeridians(meridians, labels=[0,0,0,1], fmt=\"%2.1f\")\n",
    "map.drawparallels(parallels, labels=[1,0,0,0], fmt=\"%2.1f\")\n",
    "\n",
    "## draw colorbar\n",
    "map.colorbar(colormesh, cbar_position)\n",
    "\n",
    "## draw countries...\n",
    "map.drawcountries(linewidth=0.25, color='olive')\n",
    "map.fillcontinents(color='lightgray',lake_color='aqua')\n",
    "\n",
    "    ## ... or draw the world using data from different providers (comment the previous lines!)\n",
    "#     map.arcgisimage(service='World_Shaded_Relief', xpixels = 1500, verbose=False)\n",
    "#     map.arcgisimage(service='ESRI_Imagery_World_2D', xpixels = 1500, verbose=False) \n",
    "#     map.bluemarble()\n",
    "#     map.etopo()\n",
    "#     map.shadedrelief()\n",
    "\n",
    "# set title\n",
    "title_sel = data.long_name\n",
    "timestep = np.datetime_as_string(times[0],'M')\n",
    "var_str = \"{} [{}]\".format(title_sel, data.units)\n",
    "if dataset_3D:\n",
    "    depth_str = \"{:.2f}{}\".format(float(data[depth_name]), \"[m]\")\n",
    "    title = ' - '.join((var_str, timestep, depth_str))\n",
    "else:\n",
    "    title = ' - '.join((var_str, timestep))\n",
    "    \n",
    "## draw title and axes labels\n",
    "plt.title(title, **title_fontstyle)\n",
    "plt.xlabel(xlabel, labelpad=xlabelpad, fontsize=12)\n",
    "plt.ylabel(ylabel, labelpad=ylabelpad, fontsize=12)    \n",
    "    \n",
    "# output file\n",
    "output_file = os.path.join(out_path,title.replace(' ','_')) + \".png\"\n",
    "\n",
    "# save the output file\n",
    "plt.savefig(output_file)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What the mixed layer depth map shows?\n",
    "\n",
    "The Mixed Layer Depth (MLD) represents the thickness of the layer in which the water is well mixed, so all the properties of the water are homogeneous. The MLD is important to detect areas of subsurface water mass formation.\n",
    "On this map you see that during March the MLD in the Black Sea is pretty shallow: we can see values around 20-25 m close to the Bulgarian coastline, the Crimean region and the area close to the Azov Sea. This is one of the peculiarities of the Black Sea - the vertical mixing is weak due to the strong vertical stratification. The winter convection reaches depths of about 70 m, which is the core of the Cold Intermediate Layer.\n",
    "\n",
    "Play with the colorbar (by modifying max_value in the code) to see what happens and check what is and where the maximum value is located.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "### LET'S TRY: Change the plot!\n",
    "\n",
    "If you want, you can change the above plot.\n",
    "\n",
    "For example, you could:\n",
    "- change the variable to plot\n",
    "- change the area\n",
    "- change the min/max values for the choosen variable\n",
    "- change the depth level (only for 3D datasets! ;))\n",
    "\n",
    "Try to plot salinity at 150m and temperature at 500m (what do you notice? do you see the mesoscale eddies?)\n",
    "\n",
    "Go back to [Configure the variables for the plots](#Configure-the-variables-for-the-plots) and then re-execute the cell for generating the plot. Try!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Exercise n.2: Plot of transects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go back to the \"Table of contents\"](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot transects of temperature, salinity and density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the coordinates min and max values\n",
    "depth_min = 0\n",
    "depth_max = 1000 # the MLD is not significant below this level of depth (~192m)\n",
    "lat_point = 44\n",
    "lon_min = 28.7\n",
    "lon_max = 38.55\n",
    "\n",
    "# Set the indexes of coordinates\n",
    "depth_indexes = getRangeIndexes(tem_ds.depth, depth_min, depth_max)\n",
    "lat_indexes = np.abs(lats-lat_point).argmin()\n",
    "lon_indexes = getRangeIndexes(lons, lon_min, lon_max)\n",
    "\n",
    "# Extract the coordinates subsets\n",
    "ds = tem_ds # the choosen dataset is not important now: we are extrating the coordinates\n",
    "\n",
    "lons_sel = ds[lon_name][lon_indexes]\n",
    "lats_sel = ds[lat_name][lat_indexes]\n",
    "depths_sel = -ds[depth_name][depth_indexes] # note the minus '-ds'. Why?\n",
    "\n",
    "#Avarage \n",
    "tem_ds = tem_ds[tem_name].mean('time', keep_attrs=True)\n",
    "sal_ds = sal_ds[sal_name].mean('time', keep_attrs=True)\n",
    "mld_ds = mld_ds[mld_name].mean('time', keep_attrs=True)\n",
    "\n",
    "# Set the variables to plot\n",
    "TEM = tem_ds[depth_indexes, lat_indexes, lon_indexes]\n",
    "SAL = sal_ds[depth_indexes, lat_indexes, lon_indexes]\n",
    "MLD = mld_ds[lat_indexes, lon_indexes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to check a variable content, write its name in the cell below and press RUN (or shift-enter):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the meshgrid for the plot \n",
    "X, Y = np.meshgrid(lons_sel, depths_sel)\n",
    "\n",
    "# Plot configuration\n",
    "width_inch = 14\n",
    "height_inch = 8\n",
    "\n",
    "# Axes labels\n",
    "fontsize = 14\n",
    "xlabel = \"longitude [degE]\"\n",
    "ylabel = \"depth [m]\"\n",
    "\n",
    "# Colorbar configuration\n",
    "cmap = \"jet\"\n",
    "cbar_position = \"right\"\n",
    "\n",
    "contour_levels = 100\n",
    "\n",
    "title_fontstyle = {\n",
    "    \"fontsize\": \"14\",\n",
    "    \"fontstyle\": \"italic\",\n",
    "    \"fontweight\": \"bold\",\n",
    "    \"pad\": 30\n",
    "}\n",
    "label_fontstyle = {\n",
    "    \"fontsize\": \"12\",\n",
    "#     \"labelpad\": 10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for plotting the transect (it uses many \"hidden\" variables...)\n",
    "# arguments:\n",
    "# - data: data to plot\n",
    "# - min_value\n",
    "# - max_value\n",
    "# - step_value: step in levels. If is 0, then levels = 100\n",
    "#\n",
    "def plot_transect(data, min_value, max_value, step_value):\n",
    "    fig = plt.figure(figsize=(width_inch, height_inch))\n",
    "\n",
    "    # Get the timestep\n",
    "    timestep = np.datetime_as_string(times[0],'M')\n",
    "\n",
    "    # Create the meshgrid for the plot \n",
    "    xx, yy = np.meshgrid(lons_sel, depths_sel)\n",
    "\n",
    "    # set variable limits\n",
    "    min_value = data.min().compute() if min_value is None else min_value\n",
    "    max_value = data.max().compute() if max_value is None else max_value\n",
    "   \n",
    "    contour_levels = np.arange(min_value, max_value, step_value)  if step_value > 0 else 100\n",
    "    \n",
    "    ## contour fill\n",
    "    plt.contourf(xx, yy, data, contour_levels, cmap=cmap, vmin=min_value, vmax=max_value)\n",
    "\n",
    "    colormesh = plt.pcolormesh(xx, yy, data, vmin=min_value, vmax=max_value, cmap=cmap)\n",
    "    \n",
    "    plt.grid()\n",
    "#     plt.colorbar(colormesh,extend='both')\n",
    "    plt.colorbar(extend='both')\n",
    "\n",
    "    title_sel = data.long_name\n",
    "    var_str = \"{} [{}]\".format(title_sel, data.units)\n",
    "    title = ' - '.join((var_str, timestep))\n",
    "\n",
    "    plt.title(title, **title_fontstyle)\n",
    "    plt.xlabel(xlabel, **label_fontstyle)\n",
    "    plt.ylabel(ylabel, **label_fontstyle)\n",
    "\n",
    "    # output file\n",
    "    output_file = os.path.join(out_path,title.replace(' ','_')) + \".png\"\n",
    "\n",
    "    # save the output file\n",
    "    plt.savefig(output_file)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the dataset\n",
    "data = TEM\n",
    "\n",
    "# plot the transect\n",
    "plot_transect(data, None, None, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salinity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the dataset\n",
    "data = SAL\n",
    "\n",
    "# plot the transect\n",
    "plot_transect(data, None, None, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Density and MLD comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_density(plot_data, data, MLD):\n",
    "    # def plot_transect2(data, min_value, max_value, step_value):\n",
    "    fig = plt.figure(figsize=(width_inch, height_inch))\n",
    "\n",
    "    # Get the timestep\n",
    "    timestep = np.datetime_as_string(times[0],'M')\n",
    "\n",
    "    # Create the meshgrid for the plot \n",
    "    xx, yy = np.meshgrid(lons_sel, depths_sel)\n",
    "\n",
    "    ## contour fill\n",
    "    plt.contourf(xx, yy, plot_data, contour_levels, cmap=cmap)\n",
    "\n",
    "    plt.grid()\n",
    "    plt.colorbar(extend='both')\n",
    "\n",
    "    title_sel = \"Density\"\n",
    "    units = \"kg/m^3\"\n",
    "    var_str = \"{} [{}]\".format(title_sel, units)\n",
    "    title = ' - '.join((var_str, timestep))\n",
    "\n",
    "    plt.title(title, **title_fontstyle)\n",
    "    plt.xlabel(xlabel, **label_fontstyle)\n",
    "    plt.ylabel(ylabel, **label_fontstyle)\n",
    "\n",
    "    plt.plot(X[0,:],-MLD, linewidth=2, color='black', label=\"MLD\")\n",
    "    plt.legend()\n",
    "    \n",
    "    # output file\n",
    "    output_file = os.path.join(out_path, \"_\".join((title_sel, timestep)) + \".png\")\n",
    "\n",
    "    # save the output file\n",
    "    plt.savefig(output_file)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate density\n",
    "rho = density.sigma0(SAL,TEM)\n",
    "\n",
    "data = TEM\n",
    "plot_data = rho\n",
    "\n",
    "plot_density(plot_data, data, MLD)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Exercise n.3: T, S, UV forecast timeseries at a given location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go back to the \"Table of contents\"](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of the next exercise is to visualize the forecasted timeseries of sea surface temperature, salinity and currents at a given locattion. The data are downloaded by the CMEMS website using the subsetter option with the start of the forecast 25 April 2020. There are two options:\n",
    "\n",
    "* to view the 10-days forecast with daily values\n",
    "\n",
    "* to view the 5-days forecast with hourly values \n",
    "\n",
    "Look at the example bellow for the location (29E, 43N)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for netcdf files\n",
    "data_path = './data/exercise3/'## EXERCISE 3\n",
    "\n",
    "# Input netcdf files\n",
    "\n",
    "# Daily Analysis and Forecast\n",
    "tem_d = 'bs-cmcc-tem-an-fc-d_25apr-05may.nc'\n",
    "sal_d = 'bs-cmcc-sal-an-fc-d_25apr-05may.nc'\n",
    "vel_d = 'bs-cmcc-cur-an-fc-d_25apr-05may.nc'\n",
    "\n",
    "# Hourly Analysis and Forecast\n",
    "tem_h = 'bs-cmcc-tem-an-fc-h_25apr-30apr.nc'\n",
    "sal_h = 'bs-cmcc-sal-an-fc-h_25apr-30apr.nc'\n",
    "vel_h = 'bs-cmcc-cur-an-fc-h_25apr-30apr.nc'\n",
    "\n",
    "# Build the complete nc path\n",
    "tem_d_nc = os.path.join(data_path, tem_d)\n",
    "sal_d_nc = os.path.join(data_path, sal_d)\n",
    "vel_d_nc = os.path.join(data_path, vel_d)\n",
    "\n",
    "tem_h_nc = os.path.join(data_path, tem_h)\n",
    "sal_h_nc = os.path.join(data_path, sal_h)\n",
    "vel_h_nc = os.path.join(data_path, vel_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Open the nc dataset\n",
    "tem_d_ds = xr.open_dataset(tem_d_nc)\n",
    "sal_d_ds = xr.open_dataset(sal_d_nc)\n",
    "vel_d_ds = xr.open_dataset(vel_d_nc)\n",
    "\n",
    "tem_h_ds = xr.open_dataset(tem_h_nc)\n",
    "sal_h_ds = xr.open_dataset(sal_h_nc)\n",
    "vel_h_ds = xr.open_dataset(vel_h_nc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a point.\n",
    "depth_index = 0  # Only one depth option, because of the subsetting.\n",
    "lat_index = 77  # Choose in the range from 0 to 214.\n",
    "lon_index = 40  # Choose in the range from 0 to 67.\n",
    "\n",
    "# Check point coordinates in the grid.\n",
    "var_attr = tem_d_ds['thetao'][0, depth_index, lat_index, lon_index]\n",
    "print(\"Latitude:\", var_attr.lat.values)\n",
    "print(\"Longitude:\", var_attr.lon.values)\n",
    "print(\"Depth:\", var_attr.depth.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the variables from each file.\n",
    "time_t_d = tem_d_ds.time.values\n",
    "time_s_d = sal_d_ds.time.values\n",
    "time_uv_d = vel_d_ds.time.values\n",
    "temp_d_list = tem_d_ds['thetao'][:, depth_index, lat_index, lon_index].values\n",
    "sal_d_list = sal_d_ds['so'][:, depth_index, lat_index, lon_index].values\n",
    "velx_d_list = vel_d_ds['uo'][:, depth_index, lat_index, lon_index].values\n",
    "vely_d_list = vel_d_ds['vo'][:, depth_index, lat_index, lon_index].values\n",
    "\n",
    "# The same for the hourly data:\n",
    "time_t_h = tem_h_ds.time.values\n",
    "time_s_h = sal_h_ds.time.values\n",
    "time_uv_h = vel_h_ds.time.values\n",
    "temp_h_list = tem_h_ds['thetao'][:, depth_index, lat_index, lon_index].values\n",
    "sal_h_list = sal_h_ds['so'][:, depth_index, lat_index, lon_index].values\n",
    "velx_h_list = vel_h_ds['uo'][:, depth_index, lat_index, lon_index].values\n",
    "vely_h_list = vel_h_ds['vo'][:, depth_index, lat_index, lon_index].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting function definition.\n",
    "def plot_timeseries(time_t, t, time_s, s, time_uv, u, v, title, ranges=True):\n",
    "    width_inch = 12\n",
    "    height_inch = 7\n",
    "    fig, ax = plt.subplots(figsize=(width_inch, height_inch))\n",
    "\n",
    "    color = 'tab:red'\n",
    "    ax.set_ylabel('Temperature [degC]', color=color)\n",
    "    ax.plot(time_t, t, linestyle='-', linewidth=1.5, color=color)\n",
    "    ax.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "    ax_w = ax.twinx()\n",
    "    color = 'tab:blue'\n",
    "    speed = np.sqrt(np.power(u, 2) + np.power(v, 2))\n",
    "    ax_w.quiver(time_uv, np.ones(len(time_uv))-0.6, u / speed, v / speed, width=0.002, pivot='middle', color='gray')\n",
    "    ax_w.set_ylabel('Current velocity [m/s]', color=color, labelpad=7)\n",
    "    ax_w.plot(time_uv, speed, linestyle='-', linewidth=1.5, color=color)\n",
    "    ax_w.tick_params(axis='y', labelcolor=color)\n",
    "    if ranges is True:\n",
    "        ax_w.set_ylim(0, 0.56)\n",
    "\n",
    "    ax_p = ax.twinx()\n",
    "    color = 'tab:green'\n",
    "    ax_p.set_ylabel('Salinity [psu]', color=color, labelpad=15)\n",
    "    ax_p.plot(time_s, s, linestyle='-', linewidth=1.5, color=color)\n",
    "    ax_p.tick_params(axis='y', labelcolor=color)\n",
    "    if ranges is True:\n",
    "        ax_p.set_ylim(17.81, 18.4)\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.tick_params(axis='x', labelrotation=45, pad=0)\n",
    "\n",
    "    # output file\n",
    "    output_file = os.path.join(out_path, title.replace(' ', '_')) + '.png'\n",
    "\n",
    "    # save the output file\n",
    "    plt.savefig(output_file)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot daily data.\n",
    "plot_timeseries(time_t_d, temp_d_list, time_s_d, sal_d_list,\n",
    "                time_uv_d, velx_d_list, vely_d_list, 'Timeseries with daily data', ranges=True)\n",
    "\n",
    "# Note (1): if you have chosen a different point and the some of the curves are outside the \n",
    "# plot ranges, try setting 'ranges=False' in the plot_timeseries call.\n",
    "# Note (2): If the plot appears completely blank, you have probably chosen a grid point, \n",
    "# which doesn't belong to the sea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot hourly data.\n",
    "plot_timeseries(time_t_h, temp_h_list, time_s_h, sal_h_list,\n",
    "                time_uv_h, velx_h_list, vely_h_list, 'Timeseries with hourly data', ranges=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first plot shows the 10-days forecast with a tendency of increased temperature (about 2 degC from the red curve), very slight change of salinity, and a change of the current direction from east to south and then north-western (grey arows). \n",
    "The second plot is only for 5 days, showing the same evolution but also gives the diurnal cycle as the time resolution is increased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "### LET'S TRY: Change the location!\n",
    "\n",
    "If you want, you can change the grid point by editing the variables lat_index and lon_index.\n",
    "\n",
    "Go back to [Set the coordinates](#Set-the-coordinates) \n",
    "and then re-execute the cells for generating the plot. Try!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7) Exercise n.4: Regional analysis using reanalysis product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go back to the \"Table of contents\"](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next exercise is to work with long term data, the physical reanalisys is downloaded only for the western part of the Black Sea for two depths 0 and 70 m. The subsetter option on the CMEMS website is used and the 10 years period 2009-2018 is chosen. Let us check on the average and extreme values of the temperature and currents for this period."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access the data and set the configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for netcdf files\n",
    "data_path = './data/exercise4/'\n",
    "\n",
    "# Daily data for sea surface temperature, temperature at 70 m\n",
    "# and surface current velocity in the western region for 10 years.\n",
    "sst_f = 'sst_2009-2018.nc'\n",
    "tem70m_f = 'tem70m_2009-2018.nc'\n",
    "svel_f = 'svel_2009-2018.nc'\n",
    "\n",
    "# Build the complete nc path\n",
    "sst_nc = os.path.join(data_path, sst_f)\n",
    "tem70m_nc = os.path.join(data_path, tem70m_f)\n",
    "svel_nc = os.path.join(data_path, svel_f)\n",
    "\n",
    "# Open the nc dataset\n",
    "sst_ds = xr.open_dataset(sst_nc)\n",
    "tem70m_ds = xr.open_dataset(tem70m_nc)\n",
    "svel_ds = xr.open_dataset(svel_nc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data is downloaded at one depth level only. Check to see the level for each dataset.\n",
    "print(\"Depths of temperature data (1):\", sst_ds['votemper'].depth.values)\n",
    "print(\"Depths of temperature data (2):\", tem70m_ds['votemper'].depth.values)\n",
    "print(\"Depths of currents data:\", svel_ds['vomecrty'].depth.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting function definition\n",
    "def plot_data(data, title, cbar_label, contour_levels=[0, 0]):\n",
    "    # Set the coordinate names (used later for accessing the data)\n",
    "    lon_name = 'lon'\n",
    "  ## Set the configuration  lat_name = 'lat'\n",
    "    lats = data[lat_name]\n",
    "    lons = data[lon_name]\n",
    "\n",
    "    # Set lat-lon limits - FULL AREA\n",
    "    lat_min = lats.min()\n",
    "    lat_max = lats.max()\n",
    "    lon_min = lons.min()\n",
    "    lon_max = lons.max()\n",
    "\n",
    "    # Set the coordinates indexes    # Set lat-lon limits - FULL AREA\n",
    "    lat_indexes = getRangeIndexes(lats, lat_min, lat_max)\n",
    "    lon_indexes = getRangeIndexes(lons, lon_min, lon_max)\n",
    "## Plot the variables\n",
    "    # Get the selected coordinates:\n",
    "    lats_pl = lats[lat_indexes]\n",
    "    lons_pl = lons[lon_indexes]\n",
    "\n",
    "    # Plot configuration\n",
    "    width_inch = 6\n",
    "    height_inch = 8\n",
    "\n",
    "    # Map configuration\n",
    "    map_config = {\n",
    "        #     'projection': 'merc',\n",
    "        'llcrnrlat': lat_min,\n",
    "        'llcrnrlon': lon_min,\n",
    "        'urcrnrlat': lat_max,\n",
    "        'urcrnrlon': lon_max,\n",
    "        'resolution': 'i',\n",
    "        'epsg': 4326\n",
    "    }\n",
    "\n",
    "    # Axes labels\n",
    "    fontsize = 14\n",
    "    xlabel = 'longitude [deg]'\n",
    "    ylabel = 'latitude [deg]'\n",
    "    xlabelpad = 30\n",
    "    ylabelpad = 60\n",
    "\n",
    "    # Colorbar configuration\n",
    "    cmap = 'jet'\n",
    "    cbar_position = 'right'\n",
    "\n",
    "    title_fontstyle = {\n",
    "        'fontsize': '14',\n",
    "        'fontstyle': 'italic',\n",
    "        'fontweight': 'bold',\n",
    "        'pad': 30\n",
    "    }\n",
    "\n",
    "    label_fontstyle = {\n",
    "        'fontsize': '12',\n",
    "        'labelpad': 30\n",
    "    }\n",
    "\n",
    "    plt.figure(figsize=(width_inch, height_inch))\n",
    "\n",
    "    map = Basemap(**map_config)\n",
    "\n",
    "\n",
    "    xx, yy = np.meshgrid(lons_pl, lats_pl)\n",
    "    if contour_levels == [0, 0]:\n",
    "        cs = map.contourf(xx, yy, data, cmap=cmap)\n",
    "    else:\n",
    "        cs = map.contourf(xx, yy, data, contour_levels, cmap=cmap, extend='both')\n",
    "\n",
    "    ## draw meridians and parallels\n",
    "    step_lat = float((lat_max - lat_min) / 5)\n",
    "    step_lon = float((lon_max - lon_min) / 5)\n",
    "\n",
    "    parallels = np.arange(lat_min, lat_max+step_lat, step_lat)\n",
    "    meridians = np.arange(lon_min, lon_max+step_lon, step_lon)\n",
    "\n",
    "    map.drawmeridians(meridians, labels=[0, 0, 0, 1], fmt='%2.1f')\n",
    "    map.drawparallels(parallels, labels=[1, 0, 0, 0], fmt='%2.1f')\n",
    "\n",
    "    # draw colorbar\n",
    "    cbar = map.colorbar(cs, cbar_position)\n",
    "    cbar.set_label(cbar_label, **label_fontstyle)\n",
    "\n",
    "    # draw countries...\n",
    "    map.drawcountries(linewidth=0.25, color='olive')\n",
    "    map.fillcontinents(color='lightgray', lake_color='aqua')\n",
    "\n",
    "    # draw title and axes labels\n",
    "    plt.title(title, **title_fontstyle)\n",
    "    plt.xlabel(xlabel, labelpad=xlabelpad, fontsize=12)\n",
    "    plt.ylabel(ylabel, labelpad=ylabelpad, fontsize=12)\n",
    "\n",
    "    # output file\n",
    "    output_file = os.path.join(out_path, title.replace(' ', '_')) + '.png'\n",
    "\n",
    "    # save the output file\n",
    "    plt.savefig(output_file)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the names of the variables and their units.\n",
    "variable_name = tem70m_ds['votemper'].long_name\n",
    "variable_units = tem70m_ds['votemper'].units\n",
    "tem70m_varinfo = variable_name + ' [' + variable_units + ']'\n",
    "print(tem70m_varinfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_name = sst_ds['votemper'].long_name\n",
    "variable_units = sst_ds['votemper'].units\n",
    "sst_varinfo = variable_name + ' [' + variable_units + ']'\n",
    "print(sst_varinfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_name = svel_ds['vomecrty'].long_name\n",
    "variable_units = svel_ds['vomecrty'].units\n",
    "svel_varinfo = 'current' + ' [' + variable_units + ']'\n",
    "print(svel_varinfo)\n",
    "\n",
    "# The downloaded data has only one depth level - 70 m and depth index can only be 0.\n",
    "depth_index = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sea surface temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average sea surface temperature\n",
    "mean_arr = np.mean(sst_ds['votemper'], axis=0)\n",
    "plot_data(mean_arr[depth_index, :, :], 'Average SST 2009-2018', sst_varinfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum sea surface temperature\n",
    "max_arr = np.amax(sst_ds['votemper'], axis=0)\n",
    "plot_data(max_arr[depth_index, :, :], 'Maximum SST 2009-2018', sst_varinfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum sea surface temperature\n",
    "min_arr = np.amin(sst_ds['votemper'], axis=0)\n",
    "plot_data(min_arr[depth_index, :, :], 'Minimum SST 2009-2018', sst_varinfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard deviation of sea surface temperature\n",
    "std_arr = np.std(sst_ds['votemper'], axis=0)\n",
    "plot_data(std_arr[depth_index, :, :], 'Standard deviation of SST 2009-2018', sst_varinfo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we see the maps for the averaged, minimum and maximum values, as well as the standard RMSD of the SST in the chosen region. For example the location 29E,43N iscaracterized by the mean SST of ~15.9 degC, maximum ~29.7 degC and minimum ~5.5 degC. The RMSD is ~6.7 degC which is a measure of the SST seasonal amplitude in this location (66% of the variance)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temperature at 70 m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Average temperature with contour levels\n",
    "mean_arr = np.mean(tem70m_ds['votemper'], axis=0)\n",
    "contour_levels = np.arange(8, 10, 0.2)\n",
    "plot_data(mean_arr[depth_index, :, :], 'Average Temperature 2009-2018', tem70m_varinfo, contour_levels=contour_levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum temperature\n",
    "max_arr = np.amax(tem70m_ds['votemper'], axis=0)\n",
    "plot_data(max_arr[depth_index, :, :], 'Maximum Temperature 2009-2018', tem70m_varinfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum temperature\n",
    "min_arr = np.amin(tem70m_ds['votemper'], axis=0)\n",
    "plot_data(min_arr[depth_index, :, :], 'Minimum Temperature 2009-2018', tem70m_varinfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard deviation of temperature\n",
    "std_arr = np.std(tem70m_ds['votemper'], axis=0)\n",
    "plot_data(std_arr[depth_index, :, :], 'Standard deviation of Temperature 2009-2018', tem70m_varinfo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar maps for the temperature at 70 m depth are drawn bellow. One can check what is the minimum, maximum and averaged value as well as RMSD for each grid point. In general this depth is the core of the Cold Intermediate Layer and the temperature is ~8 degC. In coldest winters the temperature could decrease bellow 7 degC. The RMSD shows typical seasonal amplitudes of ~1 degC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Surface velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average surface current velocity\n",
    "current_velocity = np.sqrt(np.power(svel_ds['vozocrtx'], 2) + np.power(svel_ds['vomecrty'], 2))\n",
    "mean_arr = np.mean(current_velocity, axis=0)\n",
    "contour_levels = np.arange(0, 0.3, 0.02)\n",
    "plot_data(mean_arr[depth_index, :, :], 'Average current velocity 2009-2018', svel_varinfo, contour_levels=contour_levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum sea surface temperature\n",
    "max_arr = np.amax(current_velocity, axis=0)\n",
    "plot_data(max_arr[depth_index, :, :], 'Maximum current velocity 2009-2018', svel_varinfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard deviation of sea surface currents\n",
    "std_arr = np.std(current_velocity, axis=0)\n",
    "plot_data(std_arr[depth_index, :, :], 'Standard deviation of current velocity 2009-2018', svel_varinfo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "For many applications it is necessary to know the variations of the current velocity. These maps are useful for the purpose. In the Black Sea the general circulation is cyclonic and the maximal flow is in the core of the Rim current, about 1 m/s. The averaged for the period current shows that the intense circulation is along the coast and the notable cape Kaliakra maximum. There is also increased current near Bosporus Strait."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8) Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go back to the \"Table of contents\"](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>CONGRATULATIONS</b><br>\n",
    "  \n",
    "--- \n",
    "\n",
    "#### Now you know how to plot the Black Sea physical model data provided by Copernicus Marine Service, for free, thanks to the European Commission.\n",
    "\n",
    "#### To go further, you can try to visualize other variables and diagnostics (spatial or vertical averages, standard deviations...)\n",
    "\n",
    "#### Hope you have enjoyed this session and let's do great science with our data.\n",
    "\n",
    "This training course is over but we'd love to hear from you about how we could improve it (topics, tools, storytelling, format, speed etc). \n",
    "\n",
    "We do thank you in advance for your kind collaboration :)"
   ]
  }
 ],
 "metadata": {
  "finalized": {
   "timestamp": 1575910772531,
   "trusted": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
